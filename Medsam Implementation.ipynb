{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ak3VeWZ7uQnr"
   },
   "source": [
    "## Medsam Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Disclaimer: \n",
    "\n",
    "This notebook includes text generated by a large language model (LLM). While I have reviewed and edited the content to the best of my ability, it is important to acknowledge the potential for inaccuracies. I encourage you to cross-check any critical information with independent sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5abd9WNvpKd"
   },
   "source": [
    "### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T23:09:43.682607300Z",
     "start_time": "2024-05-17T23:09:20.502076Z"
    },
    "execution": {
     "iopub.execute_input": "2025-03-27T22:00:21.548882Z",
     "iopub.status.busy": "2025-03-27T22:00:21.548515Z",
     "iopub.status.idle": "2025-03-27T22:00:53.708558Z",
     "shell.execute_reply": "2025-03-27T22:00:53.707284Z",
     "shell.execute_reply.started": "2025-03-27T22:00:21.548852Z"
    },
    "id": "ksz5LpCeEbsH",
    "outputId": "9f10947e-9777-4405-bb19-3bcb22f0401f",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# prompt: write me a wget code to get file from my googld drive\n",
    "\n",
    "!wget --no-check-certificate 'https://drive.usercontent.google.com/download?id=1cfORNOh_p1KHbhw8U0zhGkjSC2IrGaTB&export=download&confirm=t&uuid=c5760839-02fd-436b-9e38-9635cd7d8aab&at=APZUnTVLTsvNxsW4SInOAOYrK9ZA%3A1715907782351' -O images.zip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ckbcvUcrvxEK"
   },
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T05:29:08.446703Z",
     "iopub.status.busy": "2025-04-18T05:29:08.446183Z",
     "iopub.status.idle": "2025-04-18T05:29:08.459258Z",
     "shell.execute_reply": "2025-04-18T05:29:08.457781Z",
     "shell.execute_reply.started": "2025-04-18T05:29:08.446653Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%cd /kaggle/input/medsam-github-repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T05:29:54.925407Z",
     "iopub.status.busy": "2025-04-18T05:29:54.925072Z",
     "iopub.status.idle": "2025-04-18T05:29:54.929678Z",
     "shell.execute_reply": "2025-04-18T05:29:54.928664Z",
     "shell.execute_reply.started": "2025-04-18T05:29:54.925379Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#✅ Step 1: Add MedSAM to Python path\n",
    "import sys\n",
    "sys.path.append(\"/kaggle/input/medsam-github-repository/MedSAM-main\")\n",
    "#sys.path.append(\"/kaggle/input/medsam-github-repository/MedSAM-main/MedSAM_Inference.py\")\n",
    "sys.path.append(\"/kaggle/input/medsam-model-checkpoint/medsam_vit_b.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T23:22:57.750977Z",
     "start_time": "2024-08-02T23:22:57.741373Z"
    },
    "execution": {
     "iopub.execute_input": "2025-04-18T05:29:56.925498Z",
     "iopub.status.busy": "2025-04-18T05:29:56.924996Z",
     "iopub.status.idle": "2025-04-18T05:29:56.931559Z",
     "shell.execute_reply": "2025-04-18T05:29:56.930171Z",
     "shell.execute_reply.started": "2025-04-18T05:29:56.925435Z"
    },
    "id": "dwEMSSkBGRGI",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "IMAGE_PATH = '/kaggle/input/dataset/kaggle_3m'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T23:22:59.114930Z",
     "start_time": "2024-08-02T23:22:59.087630Z"
    },
    "execution": {
     "iopub.execute_input": "2025-04-18T05:29:58.526334Z",
     "iopub.status.busy": "2025-04-18T05:29:58.525945Z",
     "iopub.status.idle": "2025-04-18T05:29:59.300867Z",
     "shell.execute_reply": "2025-04-18T05:29:59.299932Z",
     "shell.execute_reply.started": "2025-04-18T05:29:58.526308Z"
    },
    "id": "G4NAWtOsGZ0Y",
    "outputId": "600bf250-912e-470d-efd3-14ef9100ec13",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## source: https://www.kaggle.com/code/saeedghamshadzai/image-segmentation-brain-tumor-u-net-cnn#Inferece\n",
    "import os\n",
    "paths = []\n",
    "\n",
    "for dirname in os.listdir(IMAGE_PATH):\n",
    "    if os.path.isdir(os.path.join(IMAGE_PATH, dirname)):\n",
    "\n",
    "        for filename in os.listdir(os.path.join(IMAGE_PATH, dirname)):\n",
    "            # Only the files with ',tif' format should be added to the 'paths' list\n",
    "            if filename.endswith('.tif'):\n",
    "                paths.append(IMAGE_PATH+'/'+dirname+'/'+filename)\n",
    "\n",
    "len(paths), paths[:20:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MEDSAM IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This is from the actual MedSam Inference python file\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "from segment_anything import sam_model_registry\n",
    "from segment_anything.utisl.transforms import ResizeLongestSide\n",
    "\n",
    "\n",
    "\n",
    "def medsam_inference(medsam_model, img_embed, box_1024, H, W):\n",
    "    box_torch = torch.as_tensor(box_1024, dtype=torch.float, device=img_embed.device)\n",
    "    if len(box_torch.shape) == 2:\n",
    "        box_torch = box_torch[:, None, :]  # (B, 1, 4)\n",
    "\n",
    "    sparse_embeddings, dense_embeddings = medsam_model.prompt_encoder(\n",
    "        points=None,\n",
    "        boxes=box_torch,\n",
    "        masks=None,\n",
    "    )\n",
    "    low_res_logits, _ = medsam_model.mask_decoder(\n",
    "        image_embeddings=img_embed,  # (B, 256, 64, 64)\n",
    "        image_pe=medsam_model.prompt_encoder.get_dense_pe(),  # (1, 256, 64, 64)\n",
    "        sparse_prompt_embeddings=sparse_embeddings,  # (B, 2, 256)\n",
    "        dense_prompt_embeddings=dense_embeddings,  # (B, 256, 64, 64)\n",
    "        multimask_output=False,\n",
    "    )\n",
    "\n",
    "    low_res_pred = torch.sigmoid(low_res_logits)  # (1, 1, 256, 256)\n",
    "\n",
    "    low_res_pred = F.interpolate(\n",
    "        low_res_pred,\n",
    "        size=(H, W),\n",
    "        mode=\"bilinear\",\n",
    "        align_corners=False,\n",
    "   )  # (1, 1, gt.shape)\n",
    "    low_res_pred = low_res_pred.squeeze().cpu().numpy()  # (256, 256)\n",
    "    medsam_seg = (low_res_pred > 0.5).astype(np.uint8)\n",
    "    return medsam_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T05:30:40.118797Z",
     "iopub.status.busy": "2025-04-18T05:30:40.118437Z",
     "iopub.status.idle": "2025-04-18T05:30:40.127380Z",
     "shell.execute_reply": "2025-04-18T05:30:40.126356Z",
     "shell.execute_reply.started": "2025-04-18T05:30:40.118771Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This is a generated function for a single image\n",
    "\n",
    "\n",
    "# --- Function to run MedSAM on a single image + bounding box ---\n",
    "def medsam_infer_single_image(image: np.ndarray, box: list, model, device):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        image (np.ndarray): Input image as HxW or HxWx3 (grayscale or RGB).\n",
    "        box (list): [x0, y0, x1, y1] bounding box in pixel coords.\n",
    "        model: Loaded MedSAM model.\n",
    "        device: torch.device(\"cuda\" or \"cpu\")\n",
    "    \n",
    "    Returns:\n",
    "        pred_mask (np.ndarray): Output binary mask (0 or 1), shape (H, W)\n",
    "    \"\"\"\n",
    "    \n",
    "    original_size = image.shape[:2]\n",
    "\n",
    "    # Make grayscale into RGB if needed\n",
    "    if image.ndim == 2:\n",
    "        image = np.stack([image] * 3, axis=-1)\n",
    "\n",
    "    # Resize to 1024 (MedSAM input size)\n",
    "    transform = ResizeLongestSide(1024)\n",
    "    image_resized = transform.apply_image(image)\n",
    "    image_tensor = torch.as_tensor(image_resized.transpose(2, 0, 1)).float().to(device) / 255\n",
    "    image_tensor = image_tensor.unsqueeze(0)\n",
    "\n",
    "    # Resize and normalize the box\n",
    "    box_np = np.array(box)[None, :]\n",
    "    box_tensor = torch.as_tensor(transform.apply_boxes(box_np, original_size), device=device)\n",
    "\n",
    "    # Get image embedding\n",
    "    with torch.no_grad():\n",
    "        image_embedding = model.image_encoder(image_tensor)\n",
    "\n",
    "        sparse_embeddings, dense_embeddings = model.prompt_encoder(\n",
    "            points=None,\n",
    "            boxes=box_tensor,\n",
    "            masks=None,\n",
    "        )\n",
    "\n",
    "        low_res_masks, _ = model.mask_decoder(\n",
    "            image_embeddings=image_embedding,\n",
    "            image_pe=model.prompt_encoder.get_dense_pe(),\n",
    "            sparse_prompt_embeddings=sparse_embeddings,\n",
    "            dense_prompt_embeddings=dense_embeddings,\n",
    "            multimask_output=False,\n",
    "        )\n",
    "\n",
    "        low_res_masks = torch.sigmoid(low_res_masks)\n",
    "        low_res_masks = low_res_masks.squeeze().cpu().numpy()\n",
    "\n",
    "        # Resize back to original size\n",
    "        pred_mask = cv2.resize((low_res_masks > 0.5).astype(np.uint8), (original_size[1], original_size[0]), interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "    return pred_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T23:23:06.357731Z",
     "start_time": "2024-08-02T23:23:02.351505Z"
    },
    "execution": {
     "iopub.execute_input": "2025-04-18T05:30:55.551821Z",
     "iopub.status.busy": "2025-04-18T05:30:55.551433Z",
     "iopub.status.idle": "2025-04-18T05:31:16.330522Z",
     "shell.execute_reply": "2025-04-18T05:31:16.329162Z",
     "shell.execute_reply.started": "2025-04-18T05:30:55.551794Z"
    },
    "id": "CxJ6UmsDGlK-",
    "outputId": "a92281bf-1ae6-4959-c1ef-46791b2b2156",
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## source https://www.kaggle.com/code/saeedghamshadzai/image-segmentation-brain-tumor-u-net-cnn#Inferece\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "def data_frame(data):\n",
    "    # Storing only paths that don't end with 'mask.tiff'\n",
    "    images = list(filter(lambda x: not x.endswith('mask.tif'), data))\n",
    "    # Sorting images based on the number of each MRI.\n",
    "    images.sort(key=lambda x: int(x.rsplit('_', 3)[-1][:-4]))\n",
    "    # Sorting by the patient IDs (each patient has more than 1 MRIs)\n",
    "    images.sort(key=lambda x: int(x.rsplit('_', 3)[-2]))\n",
    "\n",
    "    # Storing the image IDs\n",
    "    IDs = list(map(lambda x: x.rsplit('/', 3)[-1][:-4], images))\n",
    "\n",
    "    # Storing only paths that end with 'mask.tiff'\n",
    "    masks = list(filter(lambda x: x.endswith('mask.tif'), data))\n",
    "    # Sorting masks based on the number of each MRI.\n",
    "    masks.sort(key=lambda x: int(x.rsplit('_', 3)[-2]))\n",
    "    # Sorting by the patient IDs (each patient has more than 1 MRIs)\n",
    "    masks.sort(key=lambda x: int(x.rsplit('_', 3)[-3]))\n",
    "\n",
    "    # Opens the images\n",
    "    pixels = lambda x: Image.open(x)\n",
    "    # Selects the largest pixel\n",
    "    largest_pixel = lambda y: np.max(pixels(y))\n",
    "    # Determines if the mask contains an abnormality or not (+ or -)\n",
    "    # Remember that a negative image's mask is just an entirely black image.\n",
    "    diagnotic_function = lambda z: 1 if largest_pixel(z) > 0 else 0\n",
    "    # Storing the diagnosis corresponding to each image\n",
    "    diagnoses = list(map(lambda x: diagnotic_function(x), masks))\n",
    "\n",
    "    # Making the dataframe\n",
    "    DataFrame = pd.DataFrame({'ID': IDs, 'Image': images, 'Mask': masks, 'Diagnosis': diagnoses})\n",
    "\n",
    "    # Dividing the indexes into train, test, and validation\n",
    "    train_index, test_index = train_test_split(DataFrame.index.values.tolist(), test_size=0.15, random_state=42)\n",
    "    train_index, val_index = train_test_split(train_index, test_size=0.1, random_state=42)\n",
    "\n",
    "    # Making train, test, and validation dataframes\n",
    "    train_df, val_df, test_df = DataFrame.iloc[train_index], DataFrame.iloc[val_index], DataFrame.iloc[test_index]\n",
    "\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "# Making the dataframes\n",
    "train_df, val_df, test_df = data_frame(paths)\n",
    "\n",
    "print(len(train_df), len(val_df), len(test_df))\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T06:18:58.172479Z",
     "iopub.status.busy": "2025-04-18T06:18:58.172093Z",
     "iopub.status.idle": "2025-04-18T06:19:01.796391Z",
     "shell.execute_reply": "2025-04-18T06:19:01.795342Z",
     "shell.execute_reply.started": "2025-04-18T06:18:58.172433Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from segment_anything import sam_model_registry\n",
    "import torch\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Step 1: Initialize model WITHOUT checkpoint\n",
    "sam_model = sam_model_registry[\"vit_b\"](checkpoint=None)\n",
    "\n",
    "# Step 2: Load weights manually to the correct device\n",
    "state_dict = torch.load(\"/kaggle/input/medsam-model-checkpoint/medsam_vit_b.pth\", map_location=device)\n",
    "sam_model.load_state_dict(state_dict)\n",
    "\n",
    "# Step 3: Move model to device\n",
    "sam_model.to(device)\n",
    "sam_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T05:31:57.447739Z",
     "iopub.status.busy": "2025-04-18T05:31:57.447153Z",
     "iopub.status.idle": "2025-04-18T05:31:58.221263Z",
     "shell.execute_reply": "2025-04-18T05:31:58.219731Z",
     "shell.execute_reply.started": "2025-04-18T05:31:57.447708Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "##### Sample Image + Mask Loader for MedSAM\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Step 1: Select an image from your test set ---\n",
    "sample = test_df[test_df['Diagnosis'] == 1].iloc[0]  # pick one with tumor\n",
    "img_path = sample['Image']\n",
    "mask_path = sample['Mask']\n",
    "\n",
    "# --- Step 2: Load and resize image & mask to 256x256 ---\n",
    "img = Image.open(img_path).convert(\"L\").resize((256, 256))\n",
    "mask = Image.open(mask_path).convert(\"L\").resize((256, 256))\n",
    "\n",
    "img_np = np.array(img)\n",
    "mask_np = np.array(mask)\n",
    "\n",
    "# --- Step 3: Create bounding box from mask ---\n",
    "def get_bounding_box(mask):\n",
    "    \"\"\"Returns [x0, y0, x1, y1] box around non-zero mask pixels\"\"\"\n",
    "    y_indices, x_indices = np.where(mask > 0)\n",
    "    if len(x_indices) == 0 or len(y_indices) == 0:\n",
    "        return [0, 0, 0, 0]  # empty mask\n",
    "    return [int(x_indices.min()), int(y_indices.min()),\n",
    "            int(x_indices.max()), int(y_indices.max())]\n",
    "\n",
    "bbox = get_bounding_box(mask_np)\n",
    "\n",
    "# --- Step 4: Show image, mask, and bounding box for sanity check ---\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Image\")\n",
    "plt.imshow(img_np, cmap='gray')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Mask\")\n",
    "plt.imshow(mask_np, cmap='gray')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Bounding Box\")\n",
    "plt.imshow(img_np, cmap='gray')\n",
    "x0, y0, x1, y1 = bbox\n",
    "plt.gca().add_patch(plt.Rectangle((x0, y0), x1-x0, y1-y0, edgecolor='red', facecolor='none', lw=2))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T06:31:30.071893Z",
     "iopub.status.busy": "2025-04-18T06:31:30.071518Z",
     "iopub.status.idle": "2025-04-18T06:31:49.708202Z",
     "shell.execute_reply": "2025-04-18T06:31:49.707060Z",
     "shell.execute_reply.started": "2025-04-18T06:31:30.071863Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from segment_anything.utils.transforms import ResizeLongestSide\n",
    "\n",
    "pred_mask = medsam_infer_single_image(img_np, bbox, sam_model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T06:32:18.350665Z",
     "iopub.status.busy": "2025-04-18T06:32:18.350282Z",
     "iopub.status.idle": "2025-04-18T06:32:18.763584Z",
     "shell.execute_reply": "2025-04-18T06:32:18.762327Z",
     "shell.execute_reply.started": "2025-04-18T06:32:18.350636Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(img_np, cmap='gray')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"MedSAM Predicted Mask\")\n",
    "plt.imshow(pred_mask, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T06:33:23.369891Z",
     "iopub.status.busy": "2025-04-18T06:33:23.369527Z",
     "iopub.status.idle": "2025-04-18T06:33:23.381559Z",
     "shell.execute_reply": "2025-04-18T06:33:23.380438Z",
     "shell.execute_reply.started": "2025-04-18T06:33:23.369856Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def iou_score(pred, target, smooth=1e-6):\n",
    "    pred = torch.tensor(pred).float()\n",
    "    target = torch.tensor(target).float()\n",
    "    intersection = torch.sum(pred * target)\n",
    "    union = torch.sum(pred) + torch.sum(target) - intersection\n",
    "    return ((intersection + smooth) / (union + smooth)).item()\n",
    "\n",
    "def dice_score(pred, target, smooth=1e-6):\n",
    "    pred = torch.tensor(pred).float()\n",
    "    target = torch.tensor(target).float()\n",
    "    intersection = torch.sum(pred * target)\n",
    "    return ((2 * intersection + smooth) / (torch.sum(pred) + torch.sum(target) + smooth)).item()\n",
    "\n",
    "# Binarize ground truth mask (in case it's not 0/1)\n",
    "gt_mask_bin = (mask_np > 0).astype(np.uint8)\n",
    "\n",
    "# Calculate metrics\n",
    "iou = iou_score(pred_mask, gt_mask_bin)\n",
    "dice = dice_score(pred_mask, gt_mask_bin)\n",
    "\n",
    "print(f\"MedSAM IoU Score: {iou:.4f}\")\n",
    "print(f\"MedSAM Dice Score: {dice:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T06:57:01.190217Z",
     "iopub.status.busy": "2025-04-18T06:57:01.187859Z",
     "iopub.status.idle": "2025-04-18T07:00:20.790914Z",
     "shell.execute_reply": "2025-04-18T07:00:20.789669Z",
     "shell.execute_reply.started": "2025-04-18T06:57:01.190143Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ious = []\n",
    "dices = []\n",
    "\n",
    "# You can adjust how many images to test with\n",
    "num_samples = 10\n",
    "samples = test_df[test_df['Diagnosis'] == 1].iloc[:num_samples]\n",
    "\n",
    "for idx, row in samples.iterrows():\n",
    "    img_path = row['Image']\n",
    "    mask_path = row['Mask']\n",
    "    \n",
    "    # Load and resize image & mask\n",
    "    img = Image.open(img_path).convert(\"L\").resize((256, 256))\n",
    "    mask = Image.open(mask_path).convert(\"L\").resize((256, 256))\n",
    "    \n",
    "    img_np = np.array(img)\n",
    "    mask_np = np.array(mask)\n",
    "    gt_mask_bin = (mask_np > 0).astype(np.uint8)\n",
    "    \n",
    "    # Get bounding box from ground truth mask\n",
    "    def get_bounding_box(mask):\n",
    "        y_indices, x_indices = np.where(mask > 0)\n",
    "        if len(x_indices) == 0 or len(y_indices) == 0:\n",
    "            return [0, 0, 0, 0]  # no tumor\n",
    "        return [int(x_indices.min()), int(y_indices.min()), int(x_indices.max()), int(y_indices.max())]\n",
    "    \n",
    "    box = get_bounding_box(gt_mask_bin)\n",
    "    \n",
    "    if box == [0, 0, 0, 0]:\n",
    "        continue  # skip empty masks\n",
    "    \n",
    "    # Predict with MedSAM\n",
    "    pred_mask = medsam_infer_single_image(img_np, box, sam_model, device)\n",
    "    \n",
    "    # Evaluation\n",
    "    iou = iou_score(pred_mask, gt_mask_bin)\n",
    "    dice = dice_score(pred_mask, gt_mask_bin)\n",
    "    \n",
    "    ious.append(iou)\n",
    "    dices.append(dice)\n",
    "\n",
    "# Print results\n",
    "mean_iou = sum(ious) / len(ious)\n",
    "mean_dice = sum(dices) / len(dices)\n",
    "\n",
    "print(f\"\\n✅ MedSAM Evaluation on {len(ious)} images\")\n",
    "print(f\"Average IoU: {mean_iou:.4f}\")\n",
    "print(f\"Average Dice: {mean_dice:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-Xyv3jPv1AD"
   },
   "source": [
    "### Visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T23:23:07.038763Z",
     "start_time": "2024-08-02T23:23:06.360023Z"
    },
    "execution": {
     "iopub.execute_input": "2025-04-11T05:26:04.698914Z",
     "iopub.status.busy": "2025-04-11T05:26:04.698479Z",
     "iopub.status.idle": "2025-04-11T05:26:04.702254Z",
     "shell.execute_reply": "2025-04-11T05:26:04.701608Z",
     "shell.execute_reply.started": "2025-04-11T05:26:04.698888Z"
    },
    "id": "E2ZFo8DPQo2R",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T23:23:10.744080Z",
     "start_time": "2024-08-02T23:23:07.040813Z"
    },
    "execution": {
     "iopub.execute_input": "2025-04-11T05:26:06.516017Z",
     "iopub.status.busy": "2025-04-11T05:26:06.515732Z",
     "iopub.status.idle": "2025-04-11T05:26:10.504018Z",
     "shell.execute_reply": "2025-04-11T05:26:10.503068Z",
     "shell.execute_reply.started": "2025-04-11T05:26:06.515995Z"
    },
    "id": "HbcfuuO2Ty_k",
    "outputId": "bf4f0942-a6cc-4bb1-bfab-1c7f8c473c09",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "index = np.arange(train_df.shape[0])\n",
    "rng = np.random.default_rng(37)\n",
    "rng.shuffle(index)\n",
    "for idx in range(10):\n",
    "    image_path = train_df.iloc[index[idx]]['Image']\n",
    "    mask_path = train_df.iloc[index[idx]]['Mask']\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    mask = Image.open(mask_path).convert('L')\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax[0].imshow(image)\n",
    "    ax[1].imshow(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XwHYvFzlv6rr"
   },
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "U-Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T05:26:14.359099Z",
     "iopub.status.busy": "2025-04-11T05:26:14.358815Z",
     "iopub.status.idle": "2025-04-11T05:26:22.652686Z",
     "shell.execute_reply": "2025-04-11T05:26:22.651984Z",
     "shell.execute_reply.started": "2025-04-11T05:26:14.359076Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T05:26:40.010465Z",
     "iopub.status.busy": "2025-04-11T05:26:40.009997Z",
     "iopub.status.idle": "2025-04-11T05:26:40.016131Z",
     "shell.execute_reply": "2025-04-11T05:26:40.015486Z",
     "shell.execute_reply.started": "2025-04-11T05:26:40.010437Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Use same naming and flow as in your notebook ---\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.loc[idx, 'Image']\n",
    "        mask_path = self.df.loc[idx, 'Mask']\n",
    "\n",
    "        img = Image.open(img_path).convert('L')\n",
    "        mask = Image.open(mask_path).convert('L')\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            mask = self.transform(mask)\n",
    "\n",
    "        mask = (mask > 0).float()\n",
    "\n",
    "        return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T05:26:44.314765Z",
     "iopub.status.busy": "2025-04-11T05:26:44.314472Z",
     "iopub.status.idle": "2025-04-11T05:26:44.322708Z",
     "shell.execute_reply": "2025-04-11T05:26:44.321805Z",
     "shell.execute_reply.started": "2025-04-11T05:26:44.314742Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- U-Net Architecture (unchanged, just renamed class to match style) ---\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        def CBR(in_ch, out_ch):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "\n",
    "        self.enc1 = CBR(1, 64)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.enc2 = CBR(64, 128)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.enc3 = CBR(128, 256)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.bottleneck = CBR(256, 512)\n",
    "\n",
    "        self.up3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec3 = CBR(512, 256)\n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec2 = CBR(256, 128)\n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec1 = CBR(128, 64)\n",
    "\n",
    "        self.final = nn.Conv2d(64, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool1(e1))\n",
    "        e3 = self.enc3(self.pool2(e2))\n",
    "\n",
    "        b = self.bottleneck(self.pool3(e3))\n",
    "\n",
    "        d3 = self.dec3(torch.cat([self.up3(b), e3], dim=1))\n",
    "        d2 = self.dec2(torch.cat([self.up2(d3), e2], dim=1))\n",
    "        d1 = self.dec1(torch.cat([self.up1(d2), e1], dim=1))\n",
    "\n",
    "        return torch.sigmoid(self.final(d1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T05:26:48.983238Z",
     "iopub.status.busy": "2025-04-11T05:26:48.982913Z",
     "iopub.status.idle": "2025-04-11T05:26:48.987156Z",
     "shell.execute_reply": "2025-04-11T05:26:48.986479Z",
     "shell.execute_reply.started": "2025-04-11T05:26:48.983209Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Transforms to match 256x256 grayscale ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T05:26:50.980118Z",
     "iopub.status.busy": "2025-04-11T05:26:50.979697Z",
     "iopub.status.idle": "2025-04-11T05:26:50.985509Z",
     "shell.execute_reply": "2025-04-11T05:26:50.984646Z",
     "shell.execute_reply.started": "2025-04-11T05:26:50.980079Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Create datasets using your data_frame() function outputs ---\n",
    "train_dataset = CustomDataset(train_df, transform=transform)\n",
    "val_dataset = CustomDataset(val_df, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T05:26:51.906535Z",
     "iopub.status.busy": "2025-04-11T05:26:51.906221Z",
     "iopub.status.idle": "2025-04-11T05:26:52.382714Z",
     "shell.execute_reply": "2025-04-11T05:26:52.381833Z",
     "shell.execute_reply.started": "2025-04-11T05:26:51.906508Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Model setup and training ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T05:26:53.860100Z",
     "iopub.status.busy": "2025-04-11T05:26:53.859806Z",
     "iopub.status.idle": "2025-04-11T05:26:53.864886Z",
     "shell.execute_reply": "2025-04-11T05:26:53.864112Z",
     "shell.execute_reply.started": "2025-04-11T05:26:53.860066Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Training loop (minimal) ---\n",
    "def train_loop(model, loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T05:26:58.739181Z",
     "iopub.status.busy": "2025-04-11T05:26:58.738865Z",
     "iopub.status.idle": "2025-04-11T05:53:07.885789Z",
     "shell.execute_reply": "2025-04-11T05:53:07.885023Z",
     "shell.execute_reply.started": "2025-04-11T05:26:58.739152Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Run training ---\n",
    "for epoch in range(10):\n",
    "    epoch_loss = train_loop(model, train_loader)\n",
    "    print(f\"Epoch {epoch+1}/10 - Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "79id1y0UwB6B"
   },
   "source": [
    "Evaluating the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "This section evaluates our model's segmentation performance using two common metrics: Intersection over Union (IoU) and Dice coefficient (Dice). Both metrics quantify the overlap between predicted and ground truth segmentation masks.\n",
    "\n",
    "IoU focuses on the ratio of correctly classified pixels, while Dice emphasizes the balance between true positives and both false positives and negatives. We'll calculate these scores to assess the model's segmentation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T00:27:58.146418Z",
     "start_time": "2024-08-03T00:27:58.135444Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-04-11T05:56:03.949615Z",
     "iopub.status.busy": "2025-04-11T05:56:03.949271Z",
     "iopub.status.idle": "2025-04-11T05:56:03.954420Z",
     "shell.execute_reply": "2025-04-11T05:56:03.953714Z",
     "shell.execute_reply.started": "2025-04-11T05:56:03.949590Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def iou_score(y_true, y_pred, smooth=1e-6):\n",
    "    intersection = torch.sum(y_true * y_pred)\n",
    "    union = torch.sum(y_true) + torch.sum(y_pred) - intersection\n",
    "    iou = (intersection + smooth) / (union + smooth)\n",
    "    \n",
    "    return iou\n",
    "\n",
    "def dice_score(y_true, y_pred, smooth=1e-6):\n",
    "    intersection = torch.sum(y_true * y_pred)\n",
    "    dice = (2. * intersection + smooth) / (torch.sum(y_true) + torch.sum(y_pred) + smooth)\n",
    "    #print(dice)\n",
    "    return dice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T00:28:00.416076Z",
     "start_time": "2024-08-03T00:28:00.407649Z"
    },
    "execution": {
     "iopub.execute_input": "2025-04-11T05:56:06.454160Z",
     "iopub.status.busy": "2025-04-11T05:56:06.453883Z",
     "iopub.status.idle": "2025-04-11T05:56:06.459147Z",
     "shell.execute_reply": "2025-04-11T05:56:06.458506Z",
     "shell.execute_reply.started": "2025-04-11T05:56:06.454138Z"
    },
    "id": "Ul2c_otgwW6N",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def eval_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    ious = []\n",
    "    dices = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in test_loader:\n",
    "            images = images.float().to(device)\n",
    "            masks = masks.float().to(device)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            outputs[outputs < .5] = 0\n",
    "            outputs[outputs > .5] = 1\n",
    "\n",
    "            iou_score_val = iou_score(outputs, masks)\n",
    "            dice_score_val = dice_score(outputs, masks)\n",
    "\n",
    "            ious.append(iou_score_val)\n",
    "            dices.append(dice_score_val)\n",
    "\n",
    "    mean_iou = sum(ious) / len(ious)\n",
    "    mean_dice = sum(dices) / len(dices)\n",
    "\n",
    "\n",
    "    return mean_iou, mean_dice\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T00:31:43.005529Z",
     "start_time": "2024-08-03T00:31:40.079053Z"
    },
    "execution": {
     "iopub.execute_input": "2025-04-11T06:08:32.099322Z",
     "iopub.status.busy": "2025-04-11T06:08:32.099032Z",
     "iopub.status.idle": "2025-04-11T06:08:38.708565Z",
     "shell.execute_reply": "2025-04-11T06:08:38.707849Z",
     "shell.execute_reply.started": "2025-04-11T06:08:32.099300Z"
    },
    "id": "FJ-2_c4pwc6e",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#test_dataset = CustomDataset(test_df[test_df['Diagnosis'] == 1]['Image'].values.tolist(), test_df[test_df['Diagnosis'] == 1]['Mask'].values.tolist(), transform=transform)\n",
    "#test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "#eval_model(model, test_dataloader, device)\n",
    "\n",
    "test_df_pos = test_df[test_df['Diagnosis'] == 1]\n",
    "test_dataset = CustomDataset(test_df_pos, transform=transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "eval_model(model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T00:28:41.548752Z",
     "start_time": "2024-08-03T00:28:41.515430Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-04-11T06:08:11.619705Z",
     "iopub.status.busy": "2025-04-11T06:08:11.619405Z",
     "iopub.status.idle": "2025-04-11T06:08:11.683743Z",
     "shell.execute_reply": "2025-04-11T06:08:11.683038Z",
     "shell.execute_reply.started": "2025-04-11T06:08:11.619683Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'baseline_ckpt.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T00:31:36.173623Z",
     "start_time": "2024-08-03T00:31:36.138882Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('baseline_ckpt.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6985760,
     "sourceId": 11190195,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7112731,
     "sourceId": 11363801,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7112781,
     "sourceId": 11363864,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
